#!/usr/bin/python


"""
# (C) 2015, Chris Mutzel, <c.mutzel@f5.com>

For more information on the usage, see the project README.md

"""

import sys
#sys.path.append('/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/')
import os
import stat
import argparse
import yaml
import shutil
import itertools
import re
import json

# Augment PYTHONPATH to find Python modules relative to this file path
# This is so that we can find the modules when running from a local checkout
# installed as editable with `pip install -e ...` or `python setup.py develop`
local_module_path = os.path.abspath(
    os.path.join(os.path.dirname(__file__), '..', 'lib')
)
sys.path.append(local_module_path)


import ansible.playbook
import ansible.constants as constants
import ansible.utils.template
from ansible import errors
from ansible import callbacks
from ansible import utils
from ansible.color import ANSIBLE_COLOR, stringc
from ansible.callbacks import display

__version__ = "0.1"
__prog__ = "f5aws"

def colorize(lead, num, color):
  """ Print 'lead' = 'num' in 'color' """
  if num != 0 and ANSIBLE_COLOR and color is not None:
    return "%s%s%-15s" % (stringc(lead, color),
        stringc("=", color), stringc(str(num), color))
  else:
      return "%s=%-4s" % (lead, str(num))

def hostcolor(host, stats, color=True):
  if ANSIBLE_COLOR and color:
      if stats['failures'] != 0 or stats['unreachable'] != 0:
          return "%-37s" % stringc(host, 'red')
      elif stats['changed'] != 0:
          return "%-37s" % stringc(host, 'yellow')
      else:
          return "%-37s" % stringc(host, 'green')
  return "%-26s" % host


def get_dict_from_junk_str(inStr):
  """
      The cloudformation module outputs a yaml blob
      for the key 'invocation' in this blob, we get back
      a string like the below.
      a='stack_name="foo3-vpc" state=absent region="eu-west-1"
          template=/Users/mutzel/workspace/aws-deployments/roles/infra/files/vpc.json'
      This format is totally beyond me...
      I guess one of the quirks of ansible is that they couldn't decide on
      one type of object notation..
  """
  l = [i.split('=') for i in inStr.split(' ')]
  res_arr = [i.replace('"','') for i in list(itertools.chain(*l))]
  return dict(zip(res_arr[::2], res_arr[1::2]))

class F5Aws(object):
  """
    This class is used to execute a set of playbooks included in ./bin. 
    Playbooks are executed using the run_playbooks method, which reloads 
    inventory between each playbook.  This is slightly different than the 
    way that ansible-playbook entry point typically handles inventory during 
    a play.
  """
  def __init__(self):
    try:
      global_vars_path = '~/.{}'.format(__prog__)
      fd = open(os.path.expanduser(global_vars_path), 'r')
      self.settings = yaml.load(fd)
      if self.settings.get('install_path', None) is None:
        # TODO: better exception handling...
        raise Exception('Required variable "install_path" not found in {}'.format(global_vars_path))

      self.settings['vars_path'] = os.path.expanduser('~/vars/{}'.format(__prog__))  #~/vars/
      self.settings['env_path'] = self.settings['vars_path'] + '/env'
      self.settings['bin_path'] = self.settings['install_path'] + '/bin' #~/workspace/f5aws/bin
      #make the /env/ directory if it does not exist
      os.makedirs(self.settings['env_path'])
    except OSError:
      pass

  

  def cmd_init(self, options, extra_vars):
    """
        To instantiate a new environment, we create a set
        of inventory files for that environment. 
        
        See individual playbooks for more info. 
    """
    playbooks = ['init.yml']

    # uses the inventory included in this repository 
    inventory = self.settings['install_path']+'/inventory/hosts'
    self.run_playbooks(playbooks, inventory, options, extra_vars)

  def cmd_deploy(self, options, extra_vars):
    """
        Deploy an environment based on the set of inventory files 
        created by the 'init' command.

        See individual playbooks for more info. 
    """
    playbooks = [
      'deploy_vpc.yml',
      'deploy_az.yml',
      'deploy_app.yml',
      'deploy_bigip.yml',
#      'deploy_gtm.yml',
      'deploy_bigip_app1.yml',
      'deploy_bigip_app2.yml',
#      'deploy_client.yml'
    ]

    # uses the inventory created in ~/vars/f5aws/env/<env name> created by `init`
    inventory = '%s/%s/inventory/hosts' % (self.settings['env_path'], options.env_name)
    self.run_playbooks(playbooks, inventory, options, extra_vars)

  def cmd_teardown(self, options, extra_vars):
    """
      Complete teardown a deployed environment.
      Does not remove the inventory in ~/vars/f5aws/env/<env name>
    """
    playbooks = ['teardown_all.yml']
    
    inventory = '%s/%s/inventory/hosts' % (self.settings['env_path'], options.env_name)
    self.run_playbooks(playbooks, inventory, options, extra_vars)

  def cmd_remove(self, options, extra_vars):
    """
      Delete an environment from ~/vars/f5aws/env/<env name>
      This environment should already have been torn down using `teardown`
    """
    env = extra_vars['env_name']
    resources, statuses = self.get_env_status(env)
    
    okToRemove = True
    stillExist = []
    for r in resources: 
      if statuses[r]['state'] == 'deployed':
        okToRemove = False
        stillExist.append(r)

    if okToRemove is True:
      playbooks = ['remove.yml']

     # uses the inventory included in this repository 
      inventory = self.settings['install_path']+'/inventory/hosts'
      self.run_playbooks(playbooks, inventory, options, extra_vars)
    else:
      msg = """Cannot remove environment '%s' until all resources have been deprovisioned.
The following resources still exist: %s. 
Hint: try './bin/f5aws teardown %s'""" % (env, stillExist, env)

      display(msg, color='red', stderr=True)
        
  def cmd_list(self, options, extra_vars):
    """List all environments that have been instantiated using `init`,
         regardless of whether or not they have been deployed. 
    """
    display("Installed environments (%s):" %
      self.settings['env_path'], color='green', stderr=False) 
    envs = self.get_envs()
    if len(envs) == 0:
      display("(none)", color='red', stderr=False) 
    else:
      for env in self.get_envs():
        self.display_env_info(env)
        self.display_env_resources(env, False)
        
  def cmd_describe(self, options, extra_vars):
    """
      Provide more details on the resources associated with 
      a particular environment (vpc, subnets, bigip, app hosts, etc...)
    """
    try:
      env = extra_vars['env_name']
      self.display_env_info(env)
      self.display_env_resources(env, True)
    except IOError:
      display(" Environment '%s' does not exist" % env, color='red', stderr=True)

  def run_playbooks(self, playbooks, inventory_path, options, extra_vars):
    """
      This is a modified version of the function used within ansible-playbook.
      playbooks 
    """
    # get the absolute path for the playbooks
    playbooks = ['{}/playbooks/{}'.format(self.settings['install_path'], pb) for pb in playbooks]

    # Ansible defaults carried over from `ansible-playbook`.  Changes these
    #  shouldn't be necessary since all R/W is done within *this* users directory. 
    sshpass = None
    sudopass = None
    su_pass = None
    vault_pass = None

    for playbook in playbooks:
      if not os.path.exists(playbook):
        raise errors.AnsibleError("the playbook: %s could not be found" % playbook)
      if not (os.path.isfile(playbook) or stat.S_ISFIFO(os.stat(playbook).st_mode)):
        raise errors.AnsibleError("the playbook: %s does not appear to be a file" % playbook)

    for playbook in playbooks:
      display("Running playbook: %s" % playbook, color='green', stderr=False)
      #display("Private Key is: %s" % options.private_key_file )

      stats = callbacks.AggregateStats()
      playbook_cb = callbacks.PlaybookCallbacks(verbose=utils.VERBOSITY)
      runner_cb = callbacks.PlaybookRunnerCallbacks(stats, verbose=utils.VERBOSITY)
      inventory = ansible.inventory.Inventory(inventory_path, vault_password=vault_pass)

      if len(inventory.list_hosts()) == 0:
          raise errors.AnsibleError("provided hosts list is empty")

      pb = ansible.playbook.PlayBook(
        playbook=playbook,
        module_path=options.module_path,
        inventory=inventory,
        forks=options.forks,
        remote_user=options.remote_user,
        remote_pass=sshpass,
        callbacks=playbook_cb,
        runner_callbacks=runner_cb,
        stats=stats,
        timeout=options.timeout,
        transport=options.connection,
        sudo=options.sudo,
        sudo_user=options.sudo_user,
        sudo_pass=sudopass,
        extra_vars=extra_vars,
        #private_key_file=options.private_key_file,
        check=options.check,
        diff=options.diff,
        su=options.su,
        su_pass=su_pass,
        su_user=options.su_user,
        vault_password=vault_pass,
        force_handlers=options.force_handlers
      )

      if options.flush_cache:
        display(callbacks.banner("FLUSHING FACT CACHE"))
        pb.SETUP_CACHE.flush()

      if options.listhosts or options.listtasks or options.syntax:
        print ''
        print 'playbook: %s' % playbook
        print ''
        playnum = 0
        for (play_ds, play_basedir) in zip(pb.playbook, pb.play_basedirs):
          playnum += 1
          play = ansible.playbook.Play(pb, play_ds, play_basedir,
                                        vault_password=pb.vault_password)
          label = play.name
          hosts = pb.inventory.list_hosts(play.hosts)

          # Filter all tasks by given tags
          if pb.only_tags != 'all':
            if options.subset and not hosts:
              continue
            matched_tags, unmatched_tags = play.compare_tags(pb.only_tags)

            # Remove skipped tasks
            matched_tags = matched_tags - set(pb.skip_tags)

            unmatched_tags.discard('all')
            unknown_tags = ((set(pb.only_tags) | set(pb.skip_tags)) -
                            (matched_tags | unmatched_tags))

            if unknown_tags:
              continue

          if options.listhosts:
            print '  play #%d (%s): host count=%d' % (playnum, label, len(hosts))
            for host in hosts:
                print '    %s' % host

          if options.listtasks:
              print '  play #%d (%s):' % (playnum, label)

              for task in play.tasks():
                if (set(task.tags).intersection(pb.only_tags) and not
                  set(task.tags).intersection(pb.skip_tags)):
                  if getattr(task, 'name', None) is not None:
                    # meta tasks have no names
                    print '    %s' % task.name
          if options.listhosts or options.listtasks:
              print ''
        continue

      if options.syntax:
        # if we've not exited by now then we are fine.
        print 'Playbook Syntax is fine'
        return 0

      failed_hosts = []
      unreachable_hosts = []

      try:
        pb.run()

        hosts = sorted(pb.stats.processed.keys())
        display(callbacks.banner("PLAY RECAP"))
        playbook_cb.on_stats(pb.stats)

        for h in hosts:
          t = pb.stats.summarize(h)
          if t['failures'] > 0:
              failed_hosts.append(h)
          if t['unreachable'] > 0:
              unreachable_hosts.append(h)

        retries = failed_hosts + unreachable_hosts

        if len(retries) > 0:
          filename = pb.generate_retry_inventory(retries)
          if filename:
              display("           to retry, use: --limit @%s\n" % filename)

        for h in hosts:
          t = pb.stats.summarize(h)

          display("%s : %s %s %s %s" % (
            hostcolor(h, t),
            colorize('ok', t['ok'], 'green'),
            colorize('changed', t['changed'], 'yellow'),
            colorize('unreachable', t['unreachable'], 'red'),
            colorize('failed', t['failures'], 'red')),
            screen_only=True
          )

          display("%s : %s %s %s %s" % (
            hostcolor(h, t, False),
            colorize('ok', t['ok'], None),
            colorize('changed', t['changed'], None),
            colorize('unreachable', t['unreachable'], None),
            colorize('failed', t['failures'], None)),
            log_only=True
          )

        print ""
        if len(failed_hosts) > 0:
          return 2
        if len(unreachable_hosts) > 0:
          return 3

      except errors.AnsibleError, e:
        display("ERROR: %s" % e, color='red')
        return 1

    return 0

  def get_envs(self):
    return os.listdir(self.settings['env_path'])

  def display_env_info(self, env):
    env_info = self.get_env_info(env)
    display(" - %s" % env, color='green', stderr=False)
    for k in sorted(env_info, key=lambda key: key):
      display("    %s: %s" % (k, env_info[k]), color='green', stderr=False)

  def display_env_resources(self, env, show_resource_vars):  
      resources, statuses = self.get_env_status(env, show_resource_vars)
      display("    resources: ", color='green', stderr=False)
      for r in resources:
        if statuses[r]['state'] != 'deployed':
          color='red'
        else: 
          color='green'

        if show_resource_vars:
          display("      %s:" % r, color=color, stderr=False)
          display("        %s" % json.dumps(statuses[r], indent=10), color=color, stderr=False)
        else:
          display("      %s: %s" % (r, statuses[r]), color=color, stderr=False)

  def get_env_info(self, env):
    """Read some information about this @env from the inventory/hosts 
        file.  We do this by parsing the [all:vars] section.
    """

    env_info = {}
    # hack to get some useful information about the deployment
    with open(self.settings['env_path']+'/'+env+'/inventory/hosts', 'r') as f:
      foundVars = False
      for l in f.readlines():
        if foundVars is False:
          if 'all:vars' not in l:
            continue
          else:
            foundVars = True
        else:
          # break on the first blank line
          if l.rstrip().lstrip() == '':
            break
          else:
            result = re.match('^([a-z0-9_\-\.]+)=([a-z0-9_\-\.\/]+)', l)
            if result:
              env_info[result.group(1)] = result.group(2)
    del env_info['env_name']
    env_info['bigip_rest_password'] = '********'

    return env_info

  def get_env_status(self, env, show_resource_vars=False):
    managers = self.get_managers(env)
    statuses = {}
    resources = []
    for m in managers:
      # for each resource, we will get the results from
      #  most recent manager execution for that resource
      resource_name = m[:-8]
      resources.append(resource_name)
      try:
        with open('{}/{}/{}.yml'.format(self.settings['env_path'], env, m)) as f:
          latest = yaml.load(f)
          statuses[resource_name] = getattr(self,
              'state_'+latest['invocation']['module_name'],
              self.raise_not_implemented)(latest, show_resource_vars)
      except:
        statuses[resource_name] = {'state': 'not deployed'}

    return resources, statuses

  def get_managers(self, env ):
    """
      Returns an ordered list of all the 'managers'
      who report status via a yaml file i the ./<env>/ directory
    """
    managers = []
    # hack to get some useful information about the deployment
    
    with open(self.settings['env_path']+'/'+env+'/inventory/hosts', 'r') as f:
      foundManagers = False
      for l in f.readlines():
        if foundManagers is False:
          if '[managers]' not in l:
            continue
          else:
            foundManagers = True
        else:
          # break on the first blank line
          if l.rstrip().lstrip() == '':
            break
          else:
            result = re.match('^([a-z0-9_\-]+)', l)
            if result:
              managers.append(result.group(1))

    return managers   

  def state_cloudformation(self, latest_result, show_resource_vars):
    res_state = {}
    cf = get_dict_from_junk_str(latest_result['invocation']['module_args'])
    # we need to handle 'present' and 'absent' situations differently
    if cf['state'] == 'present':
      res_state['stack_name'] = cf['stack_name']
      if show_resource_vars:
        res_state['resource_vars'] = latest_result['stack_outputs']
      if (latest_result['output'] == 'Stack CREATE complete' or
        latest_result['output'] == 'Stack is already up-to-date.'):
        res_state['state'] = 'deployed'
      else:
        res_state['state']='deploy-error'
    else: # state == 'absent'...
      if (latest_result.get('output','') == 'Stack Deleted' or
        'does not exist' in latest_result.get('msg','')):
        res_state['state'] = 'absent'
      else:
        res_state['state'] = 'teardown-error'

    return res_state

  def raise_not_implemented(*args, **kwargs):
    raise NotImplementedError()

  def run(self):
    parser = argparse.ArgumentParser(prog='f5aws')
    parser.add_argument('-v', '--verbose', action='count', default=0,
      help='verbose mode (-vvv for more, -vvvv to enable connection debugging')
    subparsers = parser.add_subparsers(dest='cmd', help='sub-command help')
    
    parser_init = subparsers.add_parser('init',
      help='Create a new AWS deployment with F5 services.')
    parser_init.set_defaults(cmd='init')
    parser_init.add_argument('env_name',
      help='Name of the new environment to be created')
    parser_init.add_argument('-e', '--extra-vars', required=True,
      dest="extra_vars", action="append",
      help="set additional variables as key=value or YAML/JSON", default=[])
    # TODO: cleanup the variable passing for extravars so we don't need to 
    #   pass the extra-vars argument -- allow users to pass variables directly

    parser_deploy = subparsers.add_parser('deploy',
      help='Deploy EC2 resource and application services based on inventory files created using `init`.')
    parser_deploy.add_argument('env_name', metavar='ENVIRONMENT',
      type=str, help='Name of environment to be deployed/updated')
    
    parser_teardown = subparsers.add_parser('teardown',
      help='De-provision all resources in AWS EC2 for an environment created using `init`.')
    parser_teardown.add_argument('env_name', metavar='ENVIRONMENT',
      type=str, help='Name of environment to be de-provisioned. ')

    parser_remove = subparsers.add_parser('remove',
      help='Remove all inventory files for an environment created using `init`.')
    parser_remove.add_argument('env_name', metavar='ENVIRONMENT',
      type=str, help='Name of environment to be deleted')

    parser_describe = subparsers.add_parser('describe',
      help='Show resource variables along with environment information.')
    parser_describe.add_argument('env_name', metavar='ENVIRONMENT',
      type=str, help='Name of environment to describe')
    
    parser_list = subparsers.add_parser('list',
      help='List all deployments and corrosponding resource statuses.')

    options = parser.parse_args()

    for i in range(options.verbose):
      print 'Incrementing debug to level %s' % i
      utils.increment_debug(False, False, False, False)

    # additional argument handling based on the command executed
    extra_vars = {}
    if options.cmd == 'init':
      for extra_vars_opt in options.extra_vars:
        if extra_vars_opt.startswith("@"):
          # Argument is a YAML file (JSON is a subset of YAML)
          extra_vars = utils.combine_vars(extra_vars,
            utils.parse_yaml_from_file(extra_vars_opt[1:],
              vault_password=vault_pass))
        elif extra_vars_opt and extra_vars_opt[0] in '[{':
          # Arguments as YAML
          extra_vars = utils.combine_vars(extra_vars,
            utils.parse_yaml(extra_vars_opt))
        else:
          # Arguments as Key-value
          extra_vars = utils.combine_vars(extra_vars,
            utils.parse_kv(extra_vars_opt))

    if getattr(options, 'env_name', None) is not None:
      extra_vars['env_name'] = options.env_name
    extra_vars['install_path'] = self.settings['install_path']

    # Try to use key in ~/.f5aws. Otherwise, try global one defined in ansible.cfg.
    # if self.settings['private_key_file'] is not None:
    #   options.private_key_file = self.settings['private_key_file'] 
    # else: 
    #   options.private_key_file = constants.DEFAULT_PRIVATE_KEY_FILE

    # Set Key for BIGIP IAM user with limited permissions to change network 
    # (ex. reassign secondary IPs associated with VIPs)
    # options.bigip_aws_access_key_id = self.settings['bigip_aws_access_key_id']
    # options.bigip_aws_secret_access_key = self.settings['bigip_aws_secret_access_key']
 

    # Ansible expects the following variables to be defined
    #options.private_key_file = constants.DEFAULT_PRIVATE_KEY_FILE
    options.forks = constants.DEFAULT_FORKS
    options.module_path = constants.DEFAULT_MODULE_PATH
    options.remote_user = constants.DEFAULT_REMOTE_USER
    options.timeout = constants.DEFAULT_TIMEOUT
    options.connection = constants.DEFAULT_TRANSPORT
    options.sudo = constants.DEFAULT_SUDO
    options.sudo_user = None
    options.su = constants.DEFAULT_SU
    options.su_user = constants.DEFAULT_SU_USER
    options.check = False #TODO: can we make this work for some scenarios?
    options.diff = False #TODO: can we make this work for some scenarios?
    options.force_handlers = False
    options.flush_cache = False
    options.listhosts = False  #TODO: can we make this work for some scenarios?
    options.listtasks = False  #TODO: can we make this work for some scenarios?
    options.syntax = False  #TODO: can we make this work for some scenarios?

    # how about a common set of return values by all cmd functions
    getattr(self, 'cmd_'+options.cmd, self.raise_not_implemented)(options, extra_vars)

if __name__ == "__main__":
  display(" ", log_only=True)
  display(" ".join(sys.argv), log_only=True)
  display(" ", log_only=True)

  try:
    F5Aws().run()
  except errors.AnsibleError, e:
    display("ERROR: %s" % e, color='red', stderr=True)
    sys.exit(1)
  except KeyboardInterrupt, ke:
    display("ERROR: interrupted", color='red', stderr=True)
    sys.exit(1)
